{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Headline Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, LSTM, Embedding\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.applications.densenet import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"selected_sources.csv\")\n",
    "#sources_w_art = df2[['year', 'title', 'article', 'publication']]\n",
    "sources = df2[['title', 'publication']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1206821, 2)\n",
      "(1206803, 2)\n"
     ]
    }
   ],
   "source": [
    "sources.head()\n",
    "print(sources.shape)\n",
    "sources = sources[sources['title'].apply(lambda x: isinstance(x, str))]\n",
    "sources = sources[sources['title'].apply(lambda x: len(x.split()) <= 30)]\n",
    "print(sources.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIEF-Novocure presents phase 2 pilot innovate trial results suggesting tumor treating fields plus paclitaxel may be safe as first-line treatment and may improve survival of patients with recurrent ovarian cancer 30\n"
     ]
    }
   ],
   "source": [
    "max_word_count = 0\n",
    "title_with_most_words = \"\"\n",
    "for title in sources['title']:\n",
    "    if type(title) == float:\n",
    "      print(title)\n",
    "    else:\n",
    "      words = title.split()\n",
    "    \n",
    "    # Get the word count for the current title\n",
    "    word_count = len(words)\n",
    "    \n",
    "    # Check if the current title has more words than the previous maximum\n",
    "    if word_count > max_word_count:\n",
    "        max_word_count = word_count\n",
    "        title_with_most_words = title\n",
    "print(title_with_most_words, max_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Business Insider', 'CNN', 'Fox News', 'Refinery 29', 'Reuters',\n",
       "        'TMZ'], dtype=object),\n",
       " array([ 57952, 127594,  20144, 111432, 840086,  49595]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(sources['publication'], return_counts=True)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1086122,)\n",
      "(120681,)\n",
      "(1086122,)\n",
      "(120681,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets, stratified by the 'publication' category\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sources['title'],  # Features\n",
    "    sources['publication'],  # Target variable\n",
    "    test_size=0.1,  # 10% for the test set\n",
    "    stratify=sources['publication'],  # Stratify by 'publication' category\n",
    "    random_state=42  # Set a random seed for reproducibility\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1086122, 40), (120681, 40))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_num_words = 10000\n",
    "seq_len = 40\n",
    "embedding_size = 100\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_num_words) #Tokenizer is used to tokenize text\n",
    "tokenizer.fit_on_texts(X_train) #Fit this to our corpus\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(X_train) #'text to sequences converts the text to a list of indices\n",
    "x_train = pad_sequences(x_train, maxlen=40) #pad_sequences makes every sequence a fixed size list by padding with 0s \n",
    "\n",
    "\n",
    "x_test = tokenizer.texts_to_sequences(X_test) \n",
    "x_test = pad_sequences(x_test, maxlen=40)\n",
    "\n",
    "x_train.shape, x_test.shape # Check the dimensions of x_train and x_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,  331,  764, 2170,    6,\n",
       "        114,  281,  870,  558, 1391,   83,   69], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TMZ', 'Reuters', 'Refinery 29', 'CNN', 'Fox News', 'Business Insider']\n"
     ]
    }
   ],
   "source": [
    "unique_labels = list(y_train.unique())\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33942/33942 [==============================] - 1078s 32ms/step - loss: 0.3659 - accuracy: 0.8736 - val_loss: 0.3254 - val_accuracy: 0.8871\n",
      "Epoch 2/10\n",
      "33942/33942 [==============================] - 971s 29ms/step - loss: 0.2982 - accuracy: 0.8963 - val_loss: 0.3123 - val_accuracy: 0.8918\n",
      "Epoch 3/10\n",
      "33942/33942 [==============================] - 1314s 39ms/step - loss: 0.2671 - accuracy: 0.9071 - val_loss: 0.3128 - val_accuracy: 0.8924\n",
      "Epoch 4/10\n",
      "33942/33942 [==============================] - 1623s 48ms/step - loss: 0.2401 - accuracy: 0.9170 - val_loss: 0.3196 - val_accuracy: 0.8924\n",
      "Epoch 5/10\n",
      "33942/33942 [==============================] - 1008s 30ms/step - loss: 0.2148 - accuracy: 0.9261 - val_loss: 0.3360 - val_accuracy: 0.8904\n",
      "Epoch 6/10\n",
      "33942/33942 [==============================] - 1076s 32ms/step - loss: 0.1911 - accuracy: 0.9343 - val_loss: 0.3501 - val_accuracy: 0.8887\n",
      "Epoch 7/10\n",
      "33942/33942 [==============================] - 982s 29ms/step - loss: 0.1696 - accuracy: 0.9422 - val_loss: 0.3725 - val_accuracy: 0.8877\n",
      "Epoch 8/10\n",
      "33942/33942 [==============================] - 971s 29ms/step - loss: 0.1508 - accuracy: 0.9489 - val_loss: 0.4007 - val_accuracy: 0.8866\n",
      "Epoch 9/10\n",
      "33942/33942 [==============================] - 1146s 34ms/step - loss: 0.1346 - accuracy: 0.9544 - val_loss: 0.4177 - val_accuracy: 0.8834\n",
      "Epoch 10/10\n",
      "33942/33942 [==============================] - 1081s 32ms/step - loss: 0.1213 - accuracy: 0.9590 - val_loss: 0.4505 - val_accuracy: 0.8821\n",
      "3772/3772 [==============================] - 15s 4ms/step - loss: 0.4505 - accuracy: 0.8821\n",
      "Loss: 0.4504948854446411, Accuracy: 0.882094144821167\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Tokenize and pad your sequences as you have done before\n",
    "\n",
    "# Create a label encoder to encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an embedding layer to convert words to dense vectors\n",
    "model.add(Embedding(input_dim=max_num_words, output_dim=embedding_size, input_length=seq_len))\n",
    "\n",
    "# Add an LSTM layer\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "\n",
    "# Add a dense layer with softmax activation for classification\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train_encoded, epochs=10, batch_size=32, validation_data=(x_test, y_test_encoded))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test_encoded)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selected news sources\n",
    "all at least 20,000 publications\n",
    "\n",
    "<b>Everything</b>\n",
    "- Fox News (right - 20,144)\n",
    "- Reuters (center - 840,094)\n",
    "- CNN (left - 127,602)\n",
    "\n",
    "<b>Entertainment News</b>\n",
    "- TMZ (49,595)\n",
    "- Refinery29 (111,433)\n",
    "\n",
    "<b>Business</b>\n",
    "- Business Insider (57,953)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't need to run again, just for initial set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"all-the-news-2-1.csv\")\n",
    "#sources_w_art = df2[['year', 'title', 'article', 'publication']]\n",
    "sources = df2[['title', 'publication']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['Fox News', 'Vox', 'CNN', 'TMZ', 'Refinery 29', 'Business Insider']\n",
    "sources = sources.loc[sources['publication'].isin(selected)]\n",
    "sources = sources[['title', 'publication']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources.to_csv('selected_sources.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We should take concerns about the health of li...</td>\n",
       "      <td>Vox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colts GM Ryan Grigson says Andrew Luck's contr...</td>\n",
       "      <td>Business Insider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paris Hilton: Woman In Black For Uncle Monty's...</td>\n",
       "      <td>TMZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How to watch the Google I/O keynote live</td>\n",
       "      <td>Vox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>“Elizabeth Warren called me!” is turning into ...</td>\n",
       "      <td>Vox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688873</th>\n",
       "      <td>Florida Ammo Selling Out On Heels of Stay-At-H...</td>\n",
       "      <td>TMZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688874</th>\n",
       "      <td>Disney Forcing Annual Pass Holders to Continue...</td>\n",
       "      <td>TMZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688875</th>\n",
       "      <td>Nick Cannon Pimps Out His Impala with Custom N...</td>\n",
       "      <td>TMZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688876</th>\n",
       "      <td>Pete Buttigieg Says Governors Showing More Lea...</td>\n",
       "      <td>TMZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688877</th>\n",
       "      <td>Ruth Bader Ginsburg Still Working Out with Tra...</td>\n",
       "      <td>TMZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title       publication\n",
       "0        We should take concerns about the health of li...               Vox\n",
       "1        Colts GM Ryan Grigson says Andrew Luck's contr...  Business Insider\n",
       "4        Paris Hilton: Woman In Black For Uncle Monty's...               TMZ\n",
       "8                 How to watch the Google I/O keynote live               Vox\n",
       "10       “Elizabeth Warren called me!” is turning into ...               Vox\n",
       "...                                                    ...               ...\n",
       "2688873  Florida Ammo Selling Out On Heels of Stay-At-H...               TMZ\n",
       "2688874  Disney Forcing Annual Pass Holders to Continue...               TMZ\n",
       "2688875  Nick Cannon Pimps Out His Impala with Custom N...               TMZ\n",
       "2688876  Pete Buttigieg Says Governors Showing More Lea...               TMZ\n",
       "2688877  Ruth Bader Ginsburg Still Working Out with Tra...               TMZ\n",
       "\n",
       "[413999 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
