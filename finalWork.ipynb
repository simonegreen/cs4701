{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7152252,"sourceType":"datasetVersion","datasetId":4129712},{"sourceId":7178085,"sourceType":"datasetVersion","datasetId":4148434},{"sourceId":7179074,"sourceType":"datasetVersion","datasetId":4149162},{"sourceId":7186745,"sourceType":"datasetVersion","datasetId":4154845},{"sourceId":7187398,"sourceType":"datasetVersion","datasetId":4155317},{"sourceId":7193685,"sourceType":"datasetVersion","datasetId":4160048},{"sourceId":7193861,"sourceType":"datasetVersion","datasetId":4160177},{"sourceId":7193877,"sourceType":"datasetVersion","datasetId":4160192}],"dockerImageVersionId":30616,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# News Headline Generation","metadata":{}},{"cell_type":"markdown","source":"## Part 1: Data Preparation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pylab as plt\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport string\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, LSTM, Embedding\nfrom keras.layers import Conv2D, MaxPooling2D, Bidirectional\nfrom keras.optimizers import RMSprop\nfrom keras.applications.densenet import preprocess_input,decode_predictions\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import pad_sequences\nimport keras.utils as ku\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.regularizers import l2\nimport random\nfrom nltk.translate.bleu_score import SmoothingFunction, corpus_bleu\nimport itertools\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:49:31.152789Z","iopub.execute_input":"2023-12-13T16:49:31.153205Z","iopub.status.idle":"2023-12-13T16:49:31.161213Z","shell.execute_reply.started":"2023-12-13T16:49:31.153173Z","shell.execute_reply":"2023-12-13T16:49:31.160122Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"df2 = pd.read_csv(\"/kaggle/input/selected-sources/selected_sources.csv\")\nsources = df2[['title', 'publication']]","metadata":{"execution":{"iopub.status.busy":"2023-12-13T16:16:06.896575Z","iopub.execute_input":"2023-12-13T16:16:06.897234Z","iopub.status.idle":"2023-12-13T16:16:07.829660Z","shell.execute_reply.started":"2023-12-13T16:16:06.897203Z","shell.execute_reply":"2023-12-13T16:16:07.828683Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def removePunc(str):\n    str = \"\".join(i for i in str if i not in string.punctuation)\n    return str\n\nsources = sources[sources['title'].apply(lambda x: isinstance(x, str))]\nsources = sources[sources['title'].apply(lambda x: len(x.split()) <= 30)]\nsources['title'] = sources['title'].apply(lambda x: x.lower())\nsources['title'] = sources['title'].apply(lambda x: x.strip())\nsources[\"title\"] = sources['title'].apply(lambda x: removePunc(x))\nprint(sources.head)\nprint(sources.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenization & Flattening","metadata":{}},{"cell_type":"code","source":"vocabSize = 10000\ntokenizer = Tokenizer(num_words=vocabSize, oov_token = \"<OOV>\")\n\ndef textToToken(df):\n    tokenizer.fit_on_texts(df[\"title\"]) # Updating tokenizer vocabulary to only contains words in df\n    inputs = []\n    for title in df['title']:\n        tokens = tokenizer.texts_to_sequences([title])[0] # Converts all text into tokens in array form like [8, 9, 2, 10, 11, 3, 1]\n        for x in range(1, len(tokens)): # builds up n-gram sequences\n            seq = tokens[:x+1]\n            inputs.append(seq)\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:49:50.438995Z","iopub.execute_input":"2023-12-13T20:49:50.440002Z","iopub.status.idle":"2023-12-13T20:49:50.452910Z","shell.execute_reply.started":"2023-12-13T20:49:50.439962Z","shell.execute_reply":"2023-12-13T20:49:50.451859Z"},"trusted":true},"execution_count":577,"outputs":[]},{"cell_type":"markdown","source":"### Padding","metadata":{}},{"cell_type":"code","source":"def generate_oov_padded(input_sequences, total_words, oov_token_index=1):\n    max_sequence_length = max([len(x) for x in input_sequences]) # Finds longest length in order to standardize\n    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')) # adds zeros to the beginning\n\n    # Initialize lists for filtered predictors and labels\n    filtered_predictors = []\n    filtered_labels = []\n\n    for seq in input_sequences:\n        if oov_token_index != seq[-2]:  # Exclude sequences where OOV token predicts another word\n            filtered_predictors.append(seq[:-1])  # All elements except the last\n            filtered_labels.append(seq[-1])  # Only the last element\n\n    filtered_predictors = np.array(filtered_predictors) # Convert to numpy arrays\n    filtered_labels = np.array(filtered_labels)\n    filtered_labels = ku.to_categorical(filtered_labels, num_classes=total_words) # Converts each element to array of all zeros except for the label\n\n    return filtered_predictors, filtered_labels, max_sequence_length\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:50:11.718355Z","iopub.execute_input":"2023-12-13T20:50:11.718976Z","iopub.status.idle":"2023-12-13T20:50:11.726496Z","shell.execute_reply.started":"2023-12-13T20:50:11.718943Z","shell.execute_reply":"2023-12-13T20:50:11.725404Z"},"trusted":true},"execution_count":578,"outputs":[]},{"cell_type":"markdown","source":"### Text Generation Code","metadata":{}},{"cell_type":"code","source":"def temperatureSampling(preds, temperature=1.0, oov_token=\"<OOV>\"):\n    preds = np.asarray(preds).astype('float64') # convert to numpy and ensure float representation\n    oov_index = tokenizer.word_index[oov_token] # ensures that oov token wont be chosen as the word\n    preds[oov_index] = 0\n    preds = np.log(preds + 1e-8) / temperature # avoids log of 0 by adding constant. Temp represents randomness here. High temp = more random, lower temp = less random\n    exp_preds = np.exp(preds) \n    preds = exp_preds / np.sum(exp_preds) # normalizes probabilitys\n    probas = np.random.multinomial(1, preds, 1) # picks randomly from distribution with preds as the pdf\n    return np.argmax(probas)\n\ndef top_k_sampling(predictions, k=10, oov_token=\"<OOV>\"):\n    # Extract the top-k probabilities and their indices\n    oov_index = tokenizer.word_index[oov_token] # ensures that oov token wont be chosen as the word\n    predictions[oov_index] = 0\n    top_k_indices = np.argsort(predictions)[-k:] # gets top-k probabilities\n    top_k_values = predictions[top_k_indices]\n    top_k_values = top_k_values / np.sum(top_k_values) # Normalize the top-k probabilities\n    chosen_index = np.random.choice(top_k_indices, p=top_k_values) # Chose random from top-k\n    top_words = tokenizer.sequences_to_texts([[idx] for idx in top_k_indices])\n    return chosen_index\n\ndef generate_text(starter, num_words, model, max_sequence_len, temp, set_temp):\n    k=10\n    for _ in range(num_words):\n        tokenlist = tokenizer.texts_to_sequences([starter])\n        token_list = tokenizer.texts_to_sequences([starter])[0] # gets initial sequence from given word\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre') # pads to ensure proper length\n        predicted = model.predict(token_list)[0] # array of probabilities     \n        if temp:  \n            next_index = temperatureSampling(predicted, temperature = set_temp) #<- TEMP sampling\n        else:\n            next_index = top_k_sampling(predicted, k=k) # TOP K sampling\n        next_word = tokenizer.sequences_to_texts([[next_index]])[0] # converts back to word\n        starter += \" \" + next_word\n    return starter.title()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:50:57.710575Z","iopub.execute_input":"2023-12-13T20:50:57.711303Z","iopub.status.idle":"2023-12-13T20:50:57.723469Z","shell.execute_reply.started":"2023-12-13T20:50:57.711268Z","shell.execute_reply":"2023-12-13T20:50:57.722410Z"},"trusted":true},"execution_count":579,"outputs":[]},{"cell_type":"markdown","source":"## Text Similarity Metrics","metadata":{}},{"cell_type":"code","source":"# Calculate the BLEU score for reference vs generated sentences\ndef calculate_bleu_score(references, generated):\n    tokenized_refs = [[ref.split()] for ref in references]\n    tokenized_gens = [gen.split() for gen in generated]\n\n    smoothing = SmoothingFunction().method4\n    bleu_score = corpus_bleu(tokenized_refs, tokenized_gens, smoothing_function=smoothing)\n\n    return bleu_score","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:51:49.386268Z","iopub.execute_input":"2023-12-13T20:51:49.387336Z","iopub.status.idle":"2023-12-13T20:51:49.393940Z","shell.execute_reply.started":"2023-12-13T20:51:49.387286Z","shell.execute_reply":"2023-12-13T20:51:49.392797Z"},"trusted":true},"execution_count":580,"outputs":[]},{"cell_type":"markdown","source":"## Part 2: Source Specific Models","metadata":{}},{"cell_type":"markdown","source":"### Fox","metadata":{}},{"cell_type":"code","source":"foxSources = sources.loc[sources['publication'] == \"Fox News\"]\nfoxSources.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T23:30:37.398768Z","iopub.execute_input":"2023-12-12T23:30:37.399517Z","iopub.status.idle":"2023-12-12T23:30:37.464022Z","shell.execute_reply.started":"2023-12-12T23:30:37.399481Z","shell.execute_reply":"2023-12-12T23:30:37.463061Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"inputs = textToToken(foxSources)\npredictors, label, max_sequence_length = generate_oov_padded(inputs, vocabSize)\nprint(max_sequence_length)\ntrain_pred, val_pred, train_label, val_label = train_test_split(predictors, label, test_size=0.2, random_state=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"foxModel = Sequential()\ninput_len = max_sequence_length - 1\nfoxModel.add(Embedding(vocabSize, 100, input_length = input_len))\nfoxModel.add(Dropout(0.4))\nfoxModel.add(LSTM(100, return_sequences=True, kernel_regularizer=l2(0.001)))\nfoxModel.add(LSTM(100, kernel_regularizer=l2(0.001)))\nfoxModel.add(Dropout(0.4))\nfoxModel.add(Dense(vocabSize, activation='softmax'))\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\noptimizer = optimizers.Adam(learning_rate=0.001)\nfoxModel.compile(loss = 'categorical_crossentropy', optimizer=optimizer)  ","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:03:48.359219Z","iopub.execute_input":"2023-12-11T22:03:48.359637Z","iopub.status.idle":"2023-12-11T22:03:48.979140Z","shell.execute_reply.started":"2023-12-11T22:03:48.359605Z","shell.execute_reply":"2023-12-11T22:03:48.978240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"foxModel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:03:51.614232Z","iopub.execute_input":"2023-12-11T22:03:51.614605Z","iopub.status.idle":"2023-12-11T22:03:51.640205Z","shell.execute_reply.started":"2023-12-11T22:03:51.614571Z","shell.execute_reply":"2023-12-11T22:03:51.639324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"foxHistory = foxModel.fit(fox_train_pred, fox_train_label, validation_data=(fox_val_pred, fox_val_label), epochs=30, callbacks=[es, mc])","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:03:55.736971Z","iopub.execute_input":"2023-12-11T22:03:55.737375Z","iopub.status.idle":"2023-12-11T22:23:40.195001Z","shell.execute_reply.started":"2023-12-11T22:03:55.737343Z","shell.execute_reply":"2023-12-11T22:23:40.193945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"foxModel.save('foxModel1.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:23:59.755429Z","iopub.execute_input":"2023-12-11T22:23:59.755796Z","iopub.status.idle":"2023-12-11T22:23:59.906496Z","shell.execute_reply.started":"2023-12-11T22:23:59.755765Z","shell.execute_reply":"2023-12-11T22:23:59.905494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"curr = tf.keras.models.load_model('/kaggle/input/currentmodel/foxModel1.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:29:01.351761Z","iopub.execute_input":"2023-12-11T22:29:01.352699Z","iopub.status.idle":"2023-12-11T22:29:03.334929Z","shell.execute_reply.started":"2023-12-11T22:29:01.352641Z","shell.execute_reply":"2023-12-11T22:29:03.333750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(generate_text(\"united states\", 10, foxModel, max_sequence_length))\n# print(generate_text(\"donald trump\", 10, foxModel, max_sequence_length))\nprint(generate_text(\"donald\", 5, curr, max_sequence_length))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CNN","metadata":{}},{"cell_type":"code","source":"cnnSources = sources.loc[sources['publication'] == \"CNN\"]\ncnnSources.reset_index(inplace=True)\ncnnSources_random = cnnSources.sample(n=30000, random_state=30)\nprint(cnnSources.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_inputs = textToToken(cnnSources_random)\ncnn_predictors, cnn_label, cnn_max_sequence_length = generate_oov_padded(cnn_inputs, vocabSize)\ncnn_train_pred, cnn_val_pred, cnn_train_label, cnn_val_label = train_test_split(cnn_predictors, cnn_label, test_size=0.2, random_state=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnnModel = Sequential()\ninput_len = cnn_max_sequence_length - 1\ncnnModel.add(Embedding(vocabSize, 100, input_length = input_len))\ncnnModel.add(Dropout(0.4))\ncnnModel.add(LSTM(100, return_sequences=True, kernel_regularizer=l2(0.001)))\ncnnModel.add(LSTM(100, kernel_regularizer=l2(0.001)))\ncnnModel.add(Dropout(0.4))\ncnnModel.add(Dense(vocabSize, activation='softmax'))\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\noptimizer = optimizers.Adam(learning_rate=0.001)\ncnnModel.compile(loss = 'categorical_crossentropy', optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:18:37.716152Z","iopub.execute_input":"2023-12-12T02:18:37.716869Z","iopub.status.idle":"2023-12-12T02:18:41.318341Z","shell.execute_reply.started":"2023-12-12T02:18:37.716831Z","shell.execute_reply":"2023-12-12T02:18:41.317305Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"cnnHistory = cnnModel.fit(cnn_train_pred, cnn_train_label, validation_data=(cnn_val_pred, cnn_val_label), epochs=30, callbacks=[es, mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnnModel.save('cnnModel1.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(generate_text(\"vaccines are\", 5, cnnModel, cnn_max_sequence_length))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TMZ","metadata":{}},{"cell_type":"code","source":"tmzSources = sources.loc[sources['publication'] == \"TMZ\"]\ntmzSources.reset_index(inplace=True)\ntmzSources = tmzSources.sample(n=30000, random_state=30)\nprint(tmzSources.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmz_inputs = textToToken(tmzSources)\ntmz_predictors, tmz_label, tmz_max_sequence_length = generate_oov_padded(tmz_inputs, vocabSize)\nprint(tmz_max_sequence_length)\ntmz_train_pred, tmz_val_pred, tmz_train_label, tmz_val_label = train_test_split(tmz_predictors, tmz_label, test_size=0.2, random_state=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmzModel = Sequential()\ninput_len = tmz_max_sequence_length - 1\ntmzModel.add(Embedding(vocabSize, 100, input_length = input_len))\ntmzModel.add(Dropout(0.4))\ntmzModel.add(LSTM(100, return_sequences=True, kernel_regularizer=l2(0.001)))\ntmzModel.add(LSTM(100, kernel_regularizer=l2(0.001)))\ntmzModel.add(Dropout(0.4))\ntmzModel.add(Dense(vocabSize, activation='softmax'))\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\noptimizer = optimizers.Adam(learning_rate=0.001)\ntmzModel.compile(loss = 'categorical_crossentropy', optimizer=optimizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmzHistory = tmzModel.fit(tmz_train_pred, tmz_train_label, validation_data=(tmz_val_pred, tmz_val_label), epochs=30, callbacks=[es, mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmzModel.save('tmzModel1.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T17:34:00.241895Z","iopub.execute_input":"2023-12-12T17:34:00.242297Z","iopub.status.idle":"2023-12-12T17:34:00.394423Z","shell.execute_reply.started":"2023-12-12T17:34:00.242263Z","shell.execute_reply":"2023-12-12T17:34:00.393634Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(generate_text(\"donald\", 5, tmzModel, tmz_max_sequence_length))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Refinery 29","metadata":{}},{"cell_type":"code","source":"refinerySources = sources.loc[sources['publication'] == \"Refinery 29\"]\nrefinerySources.reset_index(inplace=True)\nrefinerySources = refinerySources.sample(n=30000, random_state=40)\nprint(refinerySources.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(refinerySources.head)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_inputs = textToToken(refinerySources)\nrf_predictors, rf_label, rf_max_sequence_length = generate_oov_padded(rf_inputs, vocabSize)\nrf_train_pred, rf_val_pred, rf_train_label, rf_val_label = train_test_split(rf_predictors, rf_label, test_size=0.2, random_state=30)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T23:22:40.528698Z","iopub.execute_input":"2023-12-12T23:22:40.529603Z","iopub.status.idle":"2023-12-12T23:22:47.400434Z","shell.execute_reply.started":"2023-12-12T23:22:40.529569Z","shell.execute_reply":"2023-12-12T23:22:47.399554Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"21\n","output_type":"stream"}]},{"cell_type":"code","source":"rfModel = Sequential()\ninput_len = rf_max_sequence_length - 1\nrfModel.add(Embedding(vocabSize, 100, input_length = input_len))\nrfModel.add(Dropout(0.4)) \nrfModel.add(LSTM(100, return_sequences=True, kernel_regularizer=l2(0.001)))\nrfModel.add(LSTM(100, kernel_regularizer=l2(0.001)))\nrfModel.add(Dropout(0.4))\nrfModel.add(Dense(vocabSize, activation='softmax'))\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\noptimizer = optimizers.Adam(learning_rate=0.001)\nrfModel.compile(loss = 'categorical_crossentropy', optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T19:39:34.134363Z","iopub.execute_input":"2023-12-12T19:39:34.134731Z","iopub.status.idle":"2023-12-12T19:39:34.651901Z","shell.execute_reply.started":"2023-12-12T19:39:34.134698Z","shell.execute_reply":"2023-12-12T19:39:34.650958Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"rfHistory = rfModel.fit(rf_train_pred, rf_train_label, validation_data=(rf_val_pred, rf_val_label), epochs=30, callbacks=[es, mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfModel.save('rfModel2.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T19:56:25.811859Z","iopub.execute_input":"2023-12-12T19:56:25.812953Z","iopub.status.idle":"2023-12-12T19:56:25.951290Z","shell.execute_reply.started":"2023-12-12T19:56:25.812916Z","shell.execute_reply":"2023-12-12T19:56:25.950476Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"rfTest = tf.keras.models.load_model('rfModel1.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T20:02:47.882565Z","iopub.execute_input":"2023-12-12T20:02:47.883497Z","iopub.status.idle":"2023-12-12T20:02:49.488937Z","shell.execute_reply.started":"2023-12-12T20:02:47.883460Z","shell.execute_reply":"2023-12-12T20:02:49.488103Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"print(generate_text(\"donald\", 5, rfTest, rf_max_sequence_length))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VOX","metadata":{}},{"cell_type":"code","source":"voxSources = sources.loc[sources['publication'] == \"Vox\"]\nvoxSources.reset_index(inplace=True)\nvoxSources = voxSources.sample(n=25000, random_state=30)\nprint(voxSources.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vox_inputs = textToToken(voxSources)\nvox_predictors, vox_label, vox_max_sequence_length = generate_oov_padded(vox_inputs, vocabSize)\nprint()\nvox_train_pred, vox_val_pred, vox_train_label, vox_val_label = train_test_split(vox_predictors, vox_label, test_size=0.2, random_state=30)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T20:19:38.729157Z","iopub.execute_input":"2023-12-12T20:19:38.729545Z","iopub.status.idle":"2023-12-12T20:19:48.547607Z","shell.execute_reply.started":"2023-12-12T20:19:38.729511Z","shell.execute_reply":"2023-12-12T20:19:48.546746Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"voxModel = Sequential()\ninput_len = vox_max_sequence_length - 1\nvoxModel.add(Embedding(vocabSize, 100, input_length = input_len))\nvoxModel.add(Dropout(0.4)) # dropout to avoid overfitting\nvoxModel.add(LSTM(100, return_sequences=True, kernel_regularizer=l2(0.001)))\nvoxModel.add(LSTM(100, kernel_regularizer=l2(0.001)))\nvoxModel.add(Dropout(0.4))\nvoxModel.add(Dense(vocabSize, activation='softmax'))\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\noptimizer = optimizers.Adam(learning_rate=0.001)\nvoxModel.compile(loss = 'categorical_crossentropy', optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T20:20:04.028559Z","iopub.execute_input":"2023-12-12T20:20:04.029687Z","iopub.status.idle":"2023-12-12T20:20:07.608643Z","shell.execute_reply.started":"2023-12-12T20:20:04.029649Z","shell.execute_reply":"2023-12-12T20:20:07.607754Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"voxHistory = voxModel.fit(vox_train_pred, vox_train_label, validation_data=(vox_val_pred, vox_val_label), epochs=30, callbacks=[es, mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bizModel.save('bizModel1.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T23:12:19.568522Z","iopub.execute_input":"2023-12-12T23:12:19.569388Z","iopub.status.idle":"2023-12-12T23:12:19.701955Z","shell.execute_reply.started":"2023-12-12T23:12:19.569355Z","shell.execute_reply":"2023-12-12T23:12:19.700818Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(generate_text(\"republicans\", 10, voxModel, vox_max_sequence_length))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Business Insider ","metadata":{}},{"cell_type":"code","source":"bizSources = sources.loc[sources['publication'] == \"Business Insider\"]\nbizSources.reset_index(inplace=True)\nbizSources = bizSources.sample(n=30000, random_state=40)\nprint(bizSources.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"biz_inputs = textToToken(bizSources)\nbiz_predictors, biz_label, biz_max_sequence_length = generate_oov_padded(biz_inputs, vocabSize)\nprint(biz_max_sequence_length)\nbiz_train_pred, biz_val_pred, biz_train_label, biz_val_label = train_test_split(biz_predictors, biz_label, test_size=0.2, random_state=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bizModel = Sequential()\ninput_len = biz_max_sequence_length - 1\nbizModel.add(Embedding(vocabSize, 100, input_length = input_len))\nbizModel.add(Dropout(0.4)) # dropout to avoid overfitting\nbizModel.add(LSTM(100, return_sequences=True, kernel_regularizer=l2(0.001)))\nbizModel.add(LSTM(100, kernel_regularizer=l2(0.001)))\nbizModel.add(Dropout(0.4))\nbizModel.add(Dense(vocabSize, activation='softmax'))\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\noptimizer = optimizers.Adam(learning_rate=0.001)\nbizModel.compile(loss = 'categorical_crossentropy', optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T22:40:00.552326Z","iopub.execute_input":"2023-12-12T22:40:00.553173Z","iopub.status.idle":"2023-12-12T22:40:04.299054Z","shell.execute_reply.started":"2023-12-12T22:40:00.553139Z","shell.execute_reply":"2023-12-12T22:40:04.298257Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"bizHistory = bizModel.fit(biz_train_pred, biz_train_label, validation_data=(biz_val_pred, biz_val_label), epochs=30, callbacks=[es, mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(generate_text(\"donald trump\", 8, bizModel, biz_max_sequence_length))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Completed Models and Evaluation","metadata":{}},{"cell_type":"code","source":"cnnModel = tf.keras.models.load_model(\"/kaggle/input/completedmodels/cnn_best_model.h5\")\nfoxModel = tf.keras.models.load_model(\"/kaggle/input/completedmodels/fox_best_model.h5\")\nrfModel = tf.keras.models.load_model(\"/kaggle/input/current-models/rfModel2.keras\")\ntmzModel = tf.keras.models.load_model(\"/kaggle/input/completedmodels/tmz_best_model.h5\")\nvoxModel =  tf.keras.models.load_model(\"/kaggle/input/current-models/voxModel1.keras\")\nbizModel = tf.keras.models.load_model(\"/kaggle/input/bizmodels/bizModel1.keras\")\nbizModelExtra = tf.keras.models.load_model(\"/kaggle/input/completedmodels/biz_best_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:37:36.771525Z","iopub.execute_input":"2023-12-13T20:37:36.771906Z","iopub.status.idle":"2023-12-13T20:37:42.039342Z","shell.execute_reply.started":"2023-12-13T20:37:36.771875Z","shell.execute_reply":"2023-12-13T20:37:42.038362Z"},"trusted":true},"execution_count":474,"outputs":[]},{"cell_type":"code","source":"politicalWords = [\n    \"Donald Trump\",\n    \"The Senate\",\n    \"Democrats are\",\n    \"Climate Change\",\n    \"Healthcare Reform\",\n    \"The White House\",\n    \"Foreign Affairs\",\n    \"Tax Cuts\",\n    \"Immigration Laws\",\n    \"Supreme Court\",\n    \"Gun Control\",\n    \"Civil Rights\",\n    \"Election Results\",\n    \"Trade Agreements\",\n    \"Political Campaign\",\n    \"National Security\",\n    \"Public Education\",\n    \"Foreign Aid\",\n    \"Military Spending\",\n    \"Social Justice\",\n    \"Income Inequality\",\n    \"Federal Budget\",\n    \"Global Warming\",\n    \"Hillary Clinton\",\n    \"Economic Sanctions\",\n    \n]\nprint(len(politicalWords))","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:42:15.589126Z","iopub.execute_input":"2023-12-13T17:42:15.589517Z","iopub.status.idle":"2023-12-13T17:42:15.595809Z","shell.execute_reply.started":"2023-12-13T17:42:15.589486Z","shell.execute_reply":"2023-12-13T17:42:15.594868Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"25\n","output_type":"stream"}]},{"cell_type":"code","source":"maxSeqLength = {\"rf\":21,\"vox\":27,\"biz\":28,\"cnn\":23,\"fox\":24,\"tmz\":20}","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:55:11.000686Z","iopub.execute_input":"2023-12-13T20:55:11.001659Z","iopub.status.idle":"2023-12-13T20:55:11.006947Z","shell.execute_reply.started":"2023-12-13T20:55:11.001608Z","shell.execute_reply":"2023-12-13T20:55:11.005967Z"},"trusted":true},"execution_count":582,"outputs":[]},{"cell_type":"code","source":"rfSamples = sources.loc[sources['publication'] == \"Refinery 29\"]\nrfSamples.reset_index(inplace=True)\nrfSamples = rfSamples.title\ncnnSamples = sources.loc[sources['publication'] == \"CNN\"]\ncnnSamples.reset_index(inplace=True)\ncnnSamples = cnnSamples.title\nfoxSamples = sources.loc[sources['publication'] == \"Fox News\"]\nfoxSamples.reset_index(inplace=True)\nfoxSamples = foxSamples.title\ntmzSamples = sources.loc[sources['publication'] == \"TMZ\"]\ntmzSamples.reset_index(inplace=True)\ntmzSamples = tmzSamples.title\nvoxSamples = sources.loc[sources['publication'] == \"Vox\"]\nvoxSamples.reset_index(inplace=True)\nvoxSamples = voxSamples.title\nbizSamples = sources.loc[sources['publication'] == \"Business Insider\"]\nbizSamples.reset_index(inplace=True)\nbizSamples = bizSamples.title","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:21:56.310026Z","iopub.execute_input":"2023-12-13T19:21:56.310468Z","iopub.status.idle":"2023-12-13T19:21:56.704830Z","shell.execute_reply.started":"2023-12-13T19:21:56.310435Z","shell.execute_reply":"2023-12-13T19:21:56.704032Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"def generateStatistics(modelAbv, trainedModel, titleStarter, maxLengthList, temp, setTemp):\n    bizTotals, voxTotals, cnnTotals, foxTotals, tmzTotals, rfTotals = 0,0,0,0,0,0\n    for x in range(10):\n        # Get 50 samples of each type\n        curr_vox = voxSamples.sample(n=25, random_state=x*10)\n        curr_rf = rfSamples.sample(n=25, random_state=x*10)\n        curr_cnn = cnnSamples.sample(n=25, random_state=x*10)\n        curr_fox = foxSamples.sample(n=25, random_state=x*10)\n        curr_biz = bizSamples.sample(n=25, random_state=x*10)\n        curr_tmz = tmzSamples.sample(n=25, random_state=x*10)\n        # Create generated text for the specific model \n        genText = []\n        for word in titleStarter:\n            newWords = generate_text(word, 10, trainedModel, maxLengthList[modelAbv], temp, setTemp).lower()\n            genText.append(newWords)\n\n        bizTotals += calculate_bleu_score(curr_biz, genText)\n        voxTotals += calculate_bleu_score(curr_vox, genText)\n        cnnTotals += calculate_bleu_score(curr_cnn, genText)\n        foxTotals += calculate_bleu_score(curr_fox, genText)\n        tmzTotals += calculate_bleu_score(curr_tmz, genText)\n        rfTotals += calculate_bleu_score(curr_rf, genText)\n    return [bizTotals / 10, voxTotals / 10, cnnTotals / 10, foxTotals / 10, tmzTotals / 10, rfTotals / 10]","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:52:34.428847Z","iopub.execute_input":"2023-12-13T19:52:34.429566Z","iopub.status.idle":"2023-12-13T19:52:34.438975Z","shell.execute_reply.started":"2023-12-13T19:52:34.429532Z","shell.execute_reply":"2023-12-13T19:52:34.438082Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"currTrainingData = sources.loc[sources['publication'] == \"Refinery 29\"]\nvocabList = currTrainingData.sample(n=30000, random_state=40)\nmodelInputs = textToToken(vocabList) # training tokenizer\nlen(currTrainingData)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_text(\"donald trump\", 6, rfModel, maxSeqLength[\"rf\"], True, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"currTrainingData = sources.loc[sources['publication'] == \"Vox\"]\nvocabList = currTrainingData.sample(n=30000, random_state=40)\nmodelInputs = textToToken(vocabList) # training tokenizer\n\nmodelAbv = \"rf\"\ntrainedModel = rfModel\noutputListK = generateStatistics(modelAbv, trainedModel, politicalWords, maxSeqLength, False, 0)\noutputListTemp1 = generateStatistics(modelAbv, trainedModel, politicalWords, maxSeqLength, True, 1)\noutputListTemp2 = generateStatistics(modelAbv, trainedModel, politicalWords, maxSeqLength, True, 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(outputListK)\nprint(outputListTemp1)\nprint(outputListTemp2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### selected news sources\nall at least 20,000 publications\n\n<b>Everything</b>\n- Fox News (right - 20,144)\n- Vox (left - )\n- CNN (left center - 127,602)\n\n<b>Entertainment News</b>\n- TMZ (49,595)\n- Refinery29 (111,433)\n\n<b>Business</b>\n- Business Insider (57,953)","metadata":{}},{"cell_type":"markdown","source":"### Don't need to run again period, just for initial set up","metadata":{}},{"cell_type":"code","source":"df2 = pd.read_csv(\"all-the-news-2-1.csv\")\n#sources_w_art = df2[['year', 'title', 'article', 'publication']]\nsources = df2[['title', 'publication']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected = ['Fox News', 'Vox', 'CNN', 'TMZ', 'Refinery 29', 'Business Insider']\nsources = sources.loc[sources['publication'].isin(selected)]\nsources = sources[['title', 'publication']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sources.to_csv('selected_sources.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sources","metadata":{},"execution_count":null,"outputs":[]}]}